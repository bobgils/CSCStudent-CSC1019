{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6eda832-74e3-4fad-aec8-3a4a1bbaf712",
   "metadata": {},
   "source": [
    "## World's Simplest Web Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5deb972-10ae-43be-a335-a7d2601bdaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#socket1.py\n",
    "\n",
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "print(mysock)\n",
    "print(dir(socket))\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(20)\n",
    "    if (len(data) < 1):\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "\n",
    "mysock.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea66675-1c51-493d-9c8d-d91ee56c257f",
   "metadata": {},
   "source": [
    "## Retrieving an image over HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2675dc-7e35-4ebd-b329-3254392ae422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#urljpeg.py\n",
    "\n",
    "import socket\n",
    "import time\n",
    "\n",
    "HOST = 'data.pr4e.org'\n",
    "PORT = 80\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect((HOST, PORT))\n",
    "\n",
    "#send string as byte literal using prefix \"b\"\n",
    "mysock.sendall(b'GET http://data.pr4e.org/cover3.jpg HTTP/1.0\\r\\n\\r\\n')\n",
    "count = 0\n",
    "picture = b\"\"\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(5120)\n",
    "    if (len(data) < 1): break\n",
    "    time.sleep(0.25)\n",
    "    count = count + len(data)\n",
    "    print(len(data), count)\n",
    "    picture = picture + data\n",
    "\n",
    "mysock.close()\n",
    "\n",
    "# Look for the end of the header (2 CRLF)\n",
    "pos = picture.find(b\"\\r\\n\\r\\n\")\n",
    "print('Header length', pos)\n",
    "print(picture[:pos].decode())\n",
    "\n",
    "# Skip past the header and save the picture data\n",
    "picture = picture[pos+4:]\n",
    "fhand = open(\"stuff.jpg\", \"wb\")\n",
    "fhand.write(picture)\n",
    "fhand.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f07df0-6e1a-42cd-b3a2-03421e9bff4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "#urllib1.py\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9559034-19e3-4013-af3e-0270d28885f1",
   "metadata": {},
   "source": [
    "## Retrieving web pages with urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "644a05de-5ede-49f1-a524-52b2cbf5c82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'But': 1, 'soft': 1, 'what': 1, 'light': 1, 'through': 1, 'yonder': 1, 'window': 1, 'breaks': 1, 'It': 1, 'is': 3, 'the': 3, 'east': 1, 'and': 3, 'Juliet': 1, 'sun': 2, 'Arise': 1, 'fair': 1, 'kill': 1, 'envious': 1, 'moon': 1, 'Who': 1, 'already': 1, 'sick': 1, 'pale': 1, 'with': 1, 'grief': 1}\n"
     ]
    }
   ],
   "source": [
    "#urlwords.py\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "counts = dict()\n",
    "for line in fhand:\n",
    "    words = line.decode().split()\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word, 0) + 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d24140d-8285-4917-9873-f11cb3a1e163",
   "metadata": {},
   "source": [
    "## Parsing HTML using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d4f00cb-3e9a-4060-80c5-438865124426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter -  http://www.dr-chuck.com/page1.htm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.dr-chuck.com/page2.htm\n"
     ]
    }
   ],
   "source": [
    "#urlregex.py\n",
    "\n",
    "# Search for lines that start with From and have an at sign\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import re\n",
    "\n",
    "#http://www.dr-chuck.com/page1.htm\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urllib.request.urlopen(url).read()\n",
    "links = re.findall(b'href=\"(http://.*?)\"', html)\n",
    "for link in links:\n",
    "    print(link.decode())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc28fa2-0f15-4e5d-aab4-9927dad79abc",
   "metadata": {},
   "source": [
    "## Parsing HTML using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a1c00a-5ba2-4197-81e1-11672cbf2aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page1.htm\n",
      "there are 1 paragraph tags\n",
      "<p>\n",
      "If you like, you can switch back to the \n",
      "<a href=\"page1.htm\">\n",
      "First Page</a>.\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "#urllinks.py\n",
    "\n",
    "# To run this, you can install BeautifulSoup\n",
    "# https://pypi.python.org/pypi/beautifulsoup4\n",
    "\n",
    "# Or download the file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "#url = input('Enter - ')\n",
    "url = \"http://www.dr-chuck.com/page2.htm\"\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))\n",
    "    \n",
    "tags = soup.find_all('p')\n",
    "print(\"there are %d paragraph tags\" % len(tags))\n",
    "for tag in tags:\n",
    "    print(tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43300901-5e32-46ab-8823-2ec7acafb7ea",
   "metadata": {},
   "source": [
    "## Reading binary files using urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e72e943-4f7e-42ef-b57d-a51ae7cad9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#curl1.py\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "img = urllib.request.urlopen('http://data.pr4e.org/cover3.jpg').read()\n",
    "fhand = open('cover3.jpg', 'wb')\n",
    "fhand.write(img)\n",
    "fhand.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
